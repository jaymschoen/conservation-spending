---
editor_options: 
  chunk_output_type: console
---

# Filtering of grants using stopwords

Here, we will use a list of stopwords to further refine our output from the rule-based classification
```{python eval=FALSE}
import re
import csv
import tqdm
import numpy as np
import pandas as pd

def string_found(string1, string2):
    if re.search(r"\b" + re.escape(string1) + r"\b", string2):
        return True
    return False

output_grants = 'data\\output-grants.csv'
stopwords_csv = 'data\\list-of-stopwords.csv'
output_filtered = 'data\\output-grants-filtered.csv'

output_data = pd.read_csv(output_grants)
output_data['Stopwords'] = "-"
output_data['Filtered_Categories'] = "-"

stopwords_df = pd.read_csv(stopwords_csv)
stopwords_dict = dict()
for cat in [x.strip() for x in list(stopwords_df)]:
    temp = list(set(stopwords_df[cat].dropna()))
    temp = [x.lower() for x in temp]
    stopwords_dict[cat] = temp
pbar = tqdm.tqdm(total=len(output_data))

for idx in range(len(output_data)):
    class_cats = list(output_data.iloc[idx]['Categories'].split('|'))
    stop_added = []
    flag = False

    for stop_cat in stopwords_dict.keys():
        if stop_cat in class_cats:
            for stopword in stopwords_dict[stop_cat]:
                if string_found(stopword,
                                output_data.iloc[idx]['Description'].lower()):
                    class_cats.remove(stop_cat)
                    stop_added.append(stopword)
                    break
    output_data.loc[idx,'Filtered_Categories'] = '|'.join(list(set(class_cats)))
    if len(stop_added) > 0:
        output_data.loc[idx, 'Stopwords'] = '|'.join(list(set(stop_added)))
    pbar.update(1)
pbar.close()
output_data[output_data.Stopwords != '-']
output_data.to_csv(output_filtered, index=False)
```

Following stopword filtering, we prepare a dataframe of classified grants for Exploratory Data Analysis
```{python eval=FALSE}
import pandas as pd
import numpy as np
import math
import tqdm

from sklearn.preprocessing import MultiLabelBinarizer
mlb = MultiLabelBinarizer()
data = pd.read_csv('data\\all-grants.csv')
preproc_ph = pd.read_csv('data\\list-of-preprocessing-phrases.csv')

preproc_phrases = list(preproc_ph.Phrases)
data = data.drop([ele for ele in data.columns.to_list() if ele in ['X', 'Random Sort', 'Unnamed: 0']], axis=1)
data = data.dropna(subset=['Description'])

for phrase in preproc_phrases[:6]:
    data = data[~data.Description.str.contains(phrase)]

for phrase in preproc_phrases[6:]:
    data = data[data.Description.str.lower() != phrase]

data = data.reset_index(drop=True)
data_class = pd.read_csv('data\\output-grants-filtered.csv')
data_class = data_class.fillna('-')

pbar = tqdm.tqdm(total=len(data))
for idx in range(len(data)):
    for col in data_class.columns[1:]:
        if type(data_class[col][idx]) == str:
            data_class[col][idx] = list(set(data_class[col][idx].split('|')))
    pbar.update(1)
pbar.close()
df_final = pd.concat([data, data_class[['Keywords', 'Filtered_Categories',
                                        'Bio_keywords']]],
                     axis=1)
df_final = df_final.join(pd.DataFrame(mlb.fit_transform(df_final.pop('Filtered_Categories')),columns=['cat_' + x for x in mlb.classes_],index=df_final.index))
df_final = df_final.join(pd.DataFrame(mlb.fit_transform(df_final.pop('Bio_keywords')),columns=['bio_key_' + x for x in mlb.classes_],index=df_final.index))

df_final = df_final.drop(['cat_-', 'bio_key_-'], axis=1)
df_final.to_csv('data\\classified-grants-for-analysis.csv', index=False)
```

